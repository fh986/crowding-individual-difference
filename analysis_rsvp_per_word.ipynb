{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d44a580-e398-466d-a9b2-17e3abc9db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f644fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddaa1d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total sessions:  360\n",
      "Number of subjects who completed the second session:  171\n"
     ]
    }
   ],
   "source": [
    "# Set up files\n",
    "dir_firstSess = 'data/corr_firstSess'\n",
    "files_firstSess = [f for f in os.listdir(dir_firstSess) if f.endswith('.csv')]\n",
    "\n",
    "dir_secondSess = 'data/corr_secondSess'\n",
    "files_secondSess = [f for f in os.listdir(dir_secondSess) if f.endswith('.csv')]\n",
    "\n",
    "numTotalSessions = len(files_firstSess) + len(files_secondSess)\n",
    "\n",
    "print('Number of total sessions: ', numTotalSessions)\n",
    "print('Number of subjects who completed the second session: ', len(files_secondSess))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b9b01",
   "metadata": {},
   "source": [
    "## Acquire thresholds for all tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5628276",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b006083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfComplete(mainOutput):\n",
    "    \n",
    "    complete_val = mainOutput['experimentCompleteBool'].dropna().iloc[0]\n",
    "    complete_bool = str(complete_val) == 'True'\n",
    "    if not complete_bool:\n",
    "        prolificID = mainOutput['ProlificParticipantID'].dropna().iloc[0]\n",
    "    assert complete_bool, 'Fatal: experiment not complete!'                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31cb1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsvp_responses(mydir, files): \n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    numSess = len(files)\n",
    "    \n",
    "    # for sess in range(numSess):\n",
    "    sess = 0\n",
    "    # Read the CSV file\n",
    "    file_path = os.path.join(mydir, files[sess])\n",
    "    mainOutput = pd.read_csv(file_path)\n",
    "    # checkIfComplete(mainOutput)\n",
    "\n",
    "\n",
    "    cond_threshold = {}\n",
    "    prolificID = mainOutput['ProlificParticipantID'].dropna().iloc[0]\n",
    "    \n",
    "    condition_threshold = 0\n",
    "    # Select rows where conditionName contains the RSVP foveal prefix\n",
    "    condition_data = mainOutput[mainOutput['conditionName'].str.contains('rsvp_foveal_block', na=False)]\n",
    "\n",
    "    rsvp_responses = condition_data['rsvpReadingResponsesBool'].dropna()\n",
    "    # Split each response string like '1,1,1' into three parts and store as a matrix\n",
    "    resp_list = []\n",
    "    for resp in rsvp_responses:\n",
    "        if pd.isna(resp):\n",
    "            # represent missing as [np.nan, np.nan, np.nan]\n",
    "            resp_list.append([np.nan, np.nan, np.nan])\n",
    "            continue\n",
    "        # ensure it's a string and strip whitespace\n",
    "        resp_str = str(resp).strip()\n",
    "        parts = [p.strip() for p in resp_str.split(',')]\n",
    "        # If fewer than 3 parts, pad with NaN; if more, truncate\n",
    "        parts = parts[:3] + [np.nan] * max(0, 3 - len(parts))\n",
    "        # convert to numeric where possible\n",
    "        numeric_parts = []\n",
    "        for p in parts:\n",
    "            try:\n",
    "                numeric_parts.append(int(p))\n",
    "            except Exception:\n",
    "                try:\n",
    "                    numeric_parts.append(float(p))\n",
    "                except Exception:\n",
    "                    numeric_parts.append(np.nan)\n",
    "        resp_list.append(numeric_parts)\n",
    "\n",
    "    # Convert to numpy matrix (rows=trials, cols=3)\n",
    "    if len(resp_list) > 0:\n",
    "        resp_matrix = np.array(resp_list)\n",
    "    else:\n",
    "        resp_matrix = np.empty((0, 3))\n",
    "\n",
    "    # simple check: warn if fewer than expected trials\n",
    "    if resp_matrix.shape[0] < 24:\n",
    "        print(f\"Warning: fewer than 24 trials ({resp_matrix.shape[0]}), prolificID: {prolificID}\")\n",
    "    print(resp_matrix)\n",
    "    cond_threshold['prolificID'] = prolificID\n",
    "    cond_threshold['threshold'] = condition_threshold\n",
    "    cond_threshold['rsvp_response_matrix'] = resp_matrix.tolist()\n",
    "\n",
    "    all_data.append(cond_threshold)\n",
    "\n",
    "    # all_data.append(subj_thresholds)\n",
    "    \n",
    "    all_data_df = pd.DataFrame(all_data)\n",
    "        \n",
    "    return all_data_df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256da66a",
   "metadata": {},
   "source": [
    "### Acquire thresholds:\n",
    "\n",
    "- letter acuity (log deg)\n",
    "- crowding acuity (log deg)\n",
    "- RSVP reading speed (word duration, log sec)\n",
    "- ordinary reading speed (words per min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f06e24fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [1 0 0]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 0]\n",
      " [1 1 0]\n",
      " [1 1 0]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [1 1 0]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# first session\n",
    "df_firstSess_rsvp = get_rsvp_responses(dir_firstSess, files_firstSess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b68c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# second session\n",
    "\n",
    "thresholds_rsvp_sess2 = ['rsvp_foveal_block2']\n",
    "df_secondSess_rsvp = getThresholds(dir_secondSess, files_secondSess, thresholds_rsvp_sess2, convert_to_wpm_bool=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41186e0",
   "metadata": {},
   "source": [
    "# Old codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge data frames\n",
    "\n",
    "# df_all_sessions = pd.concat([df_firstSess, df_firstSess_rsvp, df_firstSess_reading,\n",
    "#                               df_secondSess, df_secondSess_rsvp, df_secondSess_reading], ignore_index=True)\n",
    "\n",
    "# # Check if there are any 0 or negative values in df_both_sessions\n",
    "# if (df_all_sessions['threshold'] <= 0).any().any():\n",
    "#     print(\"Check if you wanted to use logged thresholds.\")\n",
    "    \n",
    "# # only keep participants who completed both sessions\n",
    "# df_both_sessions = df_all_sessions.groupby(\"prolificID\").filter(lambda g: set(g[\"repeat\"]) == {1, 2, 3, 4})\n",
    "\n",
    "# num_thresholds_per_subj = 18\n",
    "# assert df_both_sessions[\"prolificID\"].nunique() == len(df_both_sessions) / num_thresholds_per_subj, 'Fatal: Number of thresholds per subject does not match'\n",
    "\n",
    "# print(f'\\nNumber of participants with both sessions: {df_both_sessions[\"prolificID\"].nunique()}')\n",
    "\n",
    "# df_both_sessions_log = df_both_sessions.copy()\n",
    "# df_both_sessions_log['threshold'] = np.log10(df_both_sessions_log['threshold'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
