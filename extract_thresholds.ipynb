{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d44a580-e398-466d-a9b2-17e3abc9db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f644fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddaa1d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total sessions:  360\n",
      "Number of subjects who completed the second session:  171\n"
     ]
    }
   ],
   "source": [
    "# Set up files\n",
    "dir_firstSess = 'data/corr_firstSess'\n",
    "files_firstSess = [f for f in os.listdir(dir_firstSess) if f.endswith('.csv')]\n",
    "\n",
    "dir_secondSess = 'data/corr_secondSess'\n",
    "files_secondSess = [f for f in os.listdir(dir_secondSess) if f.endswith('.csv')]\n",
    "\n",
    "numTotalSessions = len(files_firstSess) + len(files_secondSess)\n",
    "\n",
    "print('Number of total sessions: ', numTotalSessions)\n",
    "print('Number of subjects who completed the second session: ', len(files_secondSess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1c7cbc-056d-4068-b4bf-eb9986afff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('------first session------')\n",
    "# for f in files_firstSess:\n",
    "#     print(f)\n",
    "    \n",
    "# print('------second session------')\n",
    "# for f in files_secondSess:\n",
    "#     print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b9b01",
   "metadata": {},
   "source": [
    "## Acquire thresholds for all tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5628276",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b006083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfComplete(mainOutput):\n",
    "    \n",
    "    complete_val = mainOutput['experimentCompleteBool'].dropna().iloc[0]\n",
    "    complete_bool = str(complete_val) == 'True'\n",
    "    if not complete_bool:\n",
    "        prolificID = mainOutput['ProlificParticipantID'].dropna().iloc[0]\n",
    "    assert complete_bool, 'Fatal: experiment not complete!'                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96846bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_condition(condition_str):\n",
    "    \"\"\"\n",
    "    Parse a condition string of the form <task>_<meridian>_block<repeat>\n",
    "    Example: 'acuity_R8_block1' -> ('acuity', 'R8', 1)\n",
    "    \"\"\"\n",
    "    match = re.match(r\"^(.*?)_(.*?)_block(\\d+)$\", condition_str)\n",
    "    if match:\n",
    "        task = match.group(1)\n",
    "        meridian = match.group(2)\n",
    "        repeat = int(match.group(3))\n",
    "        return task, meridian, repeat\n",
    "    else:\n",
    "        raise ValueError(f\"String '{condition_str}' is not in the expected format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31cb1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThresholds(mydir, files, condition_names, linear_scale_bool = True, convert_to_wpm_bool = False): # num_trials_per_staircase=35, exclude_trial_count_bool=True, exclude_questSD=True, \n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    numSess = len(files)\n",
    "    numThresholdsCat = len(condition_names)\n",
    "    \n",
    "    for sess in range(numSess):\n",
    "\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(mydir, files[sess])\n",
    "        mainOutput = pd.read_csv(file_path)\n",
    "        checkIfComplete(mainOutput)\n",
    "\n",
    "        for cat in range(numThresholdsCat):\n",
    "\n",
    "            cond_threshold = {}\n",
    "            prolificID = mainOutput['ProlificParticipantID'].dropna().iloc[0]\n",
    "            \n",
    "            condition_threshold = 0\n",
    "            condition_name = condition_names[cat]\n",
    "            taskName, meridian, repeat = parse_condition(condition_name)\n",
    "\n",
    "            condition_data = mainOutput[mainOutput['conditionName'] == condition_name]\n",
    "\n",
    "            assert(len(condition_data.questMeanAtEndOfTrialsLoop.dropna()) == 1)\n",
    "            condition_logThreshold = condition_data.questMeanAtEndOfTrialsLoop.dropna().iloc[0]\n",
    " \n",
    "            if convert_to_wpm_bool:\n",
    "                condition_logThreshold = np.log10(60) - condition_logThreshold\n",
    "            \n",
    "            if linear_scale_bool:\n",
    "                # Convert to linear scale \n",
    "                condition_threshold = 10 ** condition_logThreshold\n",
    "            else:\n",
    "                condition_threshold = condition_logThreshold\n",
    "\n",
    "            \n",
    "            # number of trials\n",
    "            trial_sent = condition_data['trialGivenToQuest']\n",
    "            num_trial_sent = sum(str(this_trial) == 'True' for this_trial in trial_sent)\n",
    "            # questSD\n",
    "            questSD = condition_data['questSDAtEndOfTrialsLoop'].dropna().iloc[0]\n",
    "\n",
    "            # if exclude_trial_count_bool: \n",
    "            #     # Count trials sent to quest\n",
    "            #     trial_sent = condition_data['trialGivenToQuest']           \n",
    "            #     num_trial_sent = sum(str(this_trial) == 'True' for this_trial in trial_sent)\n",
    "            #     num_trial_not_sent = sum(str(this_trial) == 'False' for this_trial in trial_sent)\n",
    "            #     trial_sent_bool = num_trial_sent >= num_trials_per_staircase\n",
    "            #     num_missing_line = sum(trial_sent.isna())\n",
    "            #     if not trial_sent_bool:\n",
    "            #         condition_threshold = np.nan\n",
    "                    # print(files[sess])\n",
    "                    # print(f'Warning1: not enough trials (Session {sess}, condition {condition_name})')\n",
    "                    # print(f'Num total trials: {len(trial_sent) - 1}')\n",
    "                    # print(f'Num trials missing: {num_trials_per_staircase - num_trial_sent}')\n",
    "                    # print(f'Num trials marked as not sent: {num_trial_not_sent}')\n",
    "                    # print(f'Num lines missing: {num_missing_line - 1}')\n",
    "\n",
    "            # if exclude_questSD:\n",
    "            #     questSD = condition_data['questSDAtEndOfTrialsLoop'].dropna().iloc[0]\n",
    "            #     small_questSD_bool = questSD < 0.1\n",
    "            #     if not small_questSD_bool:\n",
    "            #         condition_threshold = np.nan\n",
    "            #         # print(f'Warning2: large SD (Session {sess}, condition {condition_name}, SD = {questSD})')\n",
    "            \n",
    "            assert condition_threshold != 0, 'Fatal: Threshold not assigned'\n",
    "\n",
    "            cond_threshold['prolificID'] = prolificID\n",
    "            cond_threshold['conditionName'] = condition_name\n",
    "            cond_threshold['taskName'] = taskName\n",
    "            cond_threshold['meridian'] = meridian\n",
    "            cond_threshold['repeat'] = repeat\n",
    "            cond_threshold['threshold'] = condition_threshold\n",
    "            cond_threshold['numTrialsSent'] = num_trial_sent\n",
    "            cond_threshold['questSD'] = questSD\n",
    "            cond_threshold['readingCQAccuracy'] = np.nan\n",
    "\n",
    "            all_data.append(cond_threshold)\n",
    "        \n",
    "        # all_data.append(subj_thresholds)\n",
    "        \n",
    "        all_data_df = pd.DataFrame(all_data)\n",
    "        \n",
    "    return all_data_df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31027c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOrdReadingSpeed(mydir, files, condition_dict, sessionName):\n",
    "    '''\n",
    "    accuracy_criterion_percent: the reading speed will be marked as np.nan if the accuracy for the comprehension question\n",
    "                                is lower than this percentage\n",
    "    wpm_criteiron: the reading speed will be marked as np.nan if it is higher than this percentage\n",
    "    '''\n",
    "    \n",
    "    condition_names = list(condition_dict.keys())\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    numSess = len(files)\n",
    "    numThresholdsCat = len(condition_names)\n",
    "    \n",
    "    for sess in range(numSess):\n",
    "        \n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(mydir, files[sess])\n",
    "        mainOutput = pd.read_csv(file_path)\n",
    "        checkIfComplete(mainOutput)    \n",
    "        \n",
    "        for cat in range(numThresholdsCat):\n",
    "\n",
    "            cond_wpm = {}\n",
    "                \n",
    "            prolificID = mainOutput['ProlificParticipantID'].dropna().iloc[0]\n",
    "            \n",
    "            wordsPerMin = 0\n",
    "            condition_name = condition_names[cat]\n",
    "            taskName, meridian, repeat = parse_condition(condition_name)\n",
    "            repeat = sessionName # for reading, the repeats in one session are assigned to the same repeat\n",
    "\n",
    "            # Check if the participant answered 3 or more questions correctly\n",
    "            question_labels = condition_dict[condition_name]\n",
    "            num_questions = len(question_labels)\n",
    "            question_correct_bool = np.full(num_questions,np.nan)\n",
    "            for qq in range(num_questions):\n",
    "\n",
    "                qq_data = mainOutput[mainOutput['questionAndAnswerNickname'] == question_labels[qq]]\n",
    "                \n",
    "                question_correct_bool[qq] = (qq_data['questionAndAnswerCorrectAnswer'].item() == qq_data['questionAndAnswerResponse'].item())\n",
    "                \n",
    "            percent_correct = sum(question_correct_bool) / num_questions * 100 \n",
    "            \n",
    "            # calculate reading speed\n",
    "            speed_data = mainOutput[mainOutput['conditionName'] == condition_name]\n",
    "            numWords = speed_data['readingPageWords'].dropna()\n",
    "            reading_time = speed_data['readingPageDurationOnsetToOffsetSec'].dropna()\n",
    "\n",
    "            numWords_include = numWords[1:len(numWords)-1]  # exclude first and last page\n",
    "            reading_time_include = reading_time[1:len(reading_time)-1]\n",
    "\n",
    "            numWords_sum = numWords_include.sum()\n",
    "            reading_time_sum = reading_time_include.sum()\n",
    "\n",
    "            wordsPerMin = numWords_sum / (reading_time_sum / 60)\n",
    "\n",
    "            assert wordsPerMin != 0, 'Fatal: Threshold not assigned'\n",
    "\n",
    "            cond_wpm['prolificID'] = prolificID\n",
    "            cond_wpm['conditionName'] = condition_name\n",
    "            cond_wpm['taskName'] = taskName\n",
    "            cond_wpm['meridian'] = meridian\n",
    "            cond_wpm['repeat'] = repeat\n",
    "            cond_wpm['threshold'] = wordsPerMin\n",
    "            cond_wpm['numTrialsSent'] = np.nan\n",
    "            cond_wpm['questSD'] = np.nan\n",
    "            cond_wpm['readingCQAccuracy'] = percent_correct\n",
    "\n",
    "            all_data.append(cond_wpm)\n",
    "        \n",
    "        all_data_df = pd.DataFrame(all_data)\n",
    "        \n",
    "    return all_data_df\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256da66a",
   "metadata": {},
   "source": [
    "### Acquire thresholds:\n",
    "\n",
    "- letter acuity (log deg)\n",
    "- crowding acuity (log deg)\n",
    "- RSVP reading speed (word duration, log sec)\n",
    "- ordinary reading speed (words per min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06e24fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first session\n",
    "\n",
    "thresholds_names_sess1 = ['crowding_R8_block1','crowding_L8_block1',\n",
    "                          'crowding_R8_block2','crowding_L8_block2',\n",
    "                          'acuity_R8_block1','acuity_L8_block1']\n",
    "df_firstSess = getThresholds(dir_firstSess, files_firstSess, thresholds_names_sess1)\n",
    "\n",
    "thresholds_rsvp_sess1 = ['rsvp_foveal_block1']\n",
    "df_firstSess_rsvp = getThresholds(dir_firstSess, files_firstSess, thresholds_rsvp_sess1, convert_to_wpm_bool=True)\n",
    "\n",
    "thresholds_names_read1 = {\n",
    "        'reading_Beaver_block1': ['Beaver_1','Beaver_2','Beaver_3','Beaver_4','Beaver_5'],\n",
    "        'reading_Winter_block2': ['Winter_1','Winter_2','Winter_3','Winter_4','Winter_5']}\n",
    "df_firstSess_reading = getOrdReadingSpeed(dir_firstSess, files_firstSess, thresholds_names_read1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1b68c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# second session\n",
    "\n",
    "thresholds_names_sess2 = ['crowding_R8_block3','crowding_L8_block3',\n",
    "                          'crowding_R8_block4','crowding_L8_block4',\n",
    "                          'acuity_R8_block2','acuity_L8_block2']\n",
    "df_secondSess = getThresholds(dir_secondSess, files_secondSess, thresholds_names_sess2)\n",
    "\n",
    "thresholds_rsvp_sess2 = ['rsvp_foveal_block2']\n",
    "df_secondSess_rsvp = getThresholds(dir_secondSess, files_secondSess, thresholds_rsvp_sess2, convert_to_wpm_bool=True)\n",
    "\n",
    "thresholds_names_read2 = {\n",
    "        'reading_Desert_block1': ['Desert_1','Desert_2','Desert_3','Desert_4','Desert_5'],\n",
    "        'reading_Islands_block2': ['Islands_1','Islands_2','Islands_3','Islands_4','Islands_5']}\n",
    "df_secondSess_reading = getOrdReadingSpeed(dir_secondSess, files_secondSess, thresholds_names_read2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a6d95c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge data frames\n",
    "\n",
    "df_all_sessions = pd.concat([df_firstSess, df_firstSess_rsvp, df_firstSess_reading,\n",
    "                              df_secondSess, df_secondSess_rsvp, df_secondSess_reading], ignore_index=True)\n",
    "\n",
    "# Check if there are any 0 or negative values in df_both_sessions\n",
    "if (df_all_sessions['threshold'] <= 0).any().any():\n",
    "    print(\"Check if you wanted to use logged thresholds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d049cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of participants with both sessions: 169\n"
     ]
    }
   ],
   "source": [
    "# only keep participants who completed both sessions\n",
    "df_both_sessions = df_all_sessions.groupby(\"prolificID\").filter(lambda g: set(g[\"repeat\"]) == {1, 2, 3, 4})\n",
    "\n",
    "num_thresholds_per_subj = 18\n",
    "assert df_both_sessions[\"prolificID\"].nunique() == len(df_both_sessions) / num_thresholds_per_subj, 'Fatal: Number of thresholds per subject does not match'\n",
    "\n",
    "print(f'\\nNumber of participants with both sessions: {df_both_sessions[\"prolificID\"].nunique()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf013972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "output_path = 'tidy_both_sessions_thresholds.csv'\n",
    "df_both_sessions.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
