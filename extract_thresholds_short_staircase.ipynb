{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "266e29fa",
   "metadata": {},
   "source": [
    "This notebook extracts thresholds predicted by quest after every trial. \n",
    "It saves the results in a long form (each row is a threshold), named \"tidy_both_sessions_per_trial_log.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d44a580-e398-466d-a9b2-17e3abc9db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f644fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddaa1d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total sessions:  360\n",
      "Number of subjects who completed the second session:  171\n"
     ]
    }
   ],
   "source": [
    "# Set up files\n",
    "dir_firstSess = 'data/corr_firstSess'\n",
    "files_firstSess = [f for f in os.listdir(dir_firstSess) if f.endswith('.csv')]\n",
    "\n",
    "dir_secondSess = 'data/corr_secondSess'\n",
    "files_secondSess = [f for f in os.listdir(dir_secondSess) if f.endswith('.csv')]\n",
    "\n",
    "numTotalSessions = len(files_firstSess) + len(files_secondSess)\n",
    "\n",
    "print('Number of total sessions: ', numTotalSessions)\n",
    "print('Number of subjects who completed the second session: ', len(files_secondSess))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b9b01",
   "metadata": {},
   "source": [
    "## Acquire thresholds for all tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5628276",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b006083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfComplete(mainOutput):\n",
    "    \n",
    "    complete_val = mainOutput['experimentCompleteBool'].dropna().iloc[0]\n",
    "    complete_bool = str(complete_val) == 'True'\n",
    "    if not complete_bool:\n",
    "        prolificID = mainOutput['ProlificParticipantID'].dropna().iloc[0]\n",
    "    assert complete_bool, 'Fatal: experiment not complete!'                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96846bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_condition(condition_str):\n",
    "    \"\"\"\n",
    "    Parse a condition string of the form <task>_<meridian>_block<repeat>\n",
    "    Example: 'acuity_R8_block1' -> ('acuity', 'R8', 1)\n",
    "    \"\"\"\n",
    "    match = re.match(r\"^(.*?)_(.*?)_block(\\d+)$\", condition_str)\n",
    "    if match:\n",
    "        task = match.group(1)\n",
    "        meridian = match.group(2)\n",
    "        repeat = int(match.group(3))\n",
    "        return task, meridian, repeat\n",
    "    else:\n",
    "        raise ValueError(f\"String '{condition_str}' is not in the expected format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31cb1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThresholds(mydir, files, condition_names, linear_scale_bool = False, staircase_length = 12, convert_to_wpm_bool = False): # num_trials_per_staircase=35, exclude_trial_count_bool=True, exclude_questSD=True, \n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    numSess = len(files)\n",
    "    numThresholdsCat = len(condition_names)\n",
    "\n",
    "    for sess in range(numSess):\n",
    "\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(mydir, files[sess])\n",
    "        mainOutput = pd.read_csv(file_path)\n",
    "        checkIfComplete(mainOutput)\n",
    "\n",
    "        for cat in range(numThresholdsCat):\n",
    "\n",
    "            cond_threshold = {}\n",
    "            prolificID = mainOutput['ProlificParticipantID'].dropna().iloc[0]\n",
    "            assert prolificID, 'Fatal: no prolificID'\n",
    "\n",
    "            condition_threshold = 0\n",
    "            condition_name = condition_names[cat]\n",
    "            taskName, meridian, repeat = parse_condition(condition_name)\n",
    "\n",
    "            condition_data = mainOutput[mainOutput['conditionName'] == condition_name]\n",
    "\n",
    "            condition_data_filtered = condition_data[condition_data['trialGivenToQuest'] == True]\n",
    "            condition_staircase_full = condition_data_filtered['questMeanBeforeThisTrialResponse'].dropna()\n",
    "\n",
    "            if len(condition_staircase_full) > staircase_length - 1:\n",
    "                condition_logThreshold = condition_staircase_full.iloc[staircase_length - 1]\n",
    "            elif len(condition_staircase_full) == 0:\n",
    "                print('Warning: No trials sent to QUEST (file name: {}, condition {})'.format(files[sess], condition_name))\n",
    "                condition_logThreshold = np.nan\n",
    "            else:\n",
    "                condition_logThreshold = condition_staircase_full.iloc[-1]\n",
    "            assert np.isscalar(condition_logThreshold), \"Threshold extraction did not return a single value\"\n",
    "\n",
    "            if convert_to_wpm_bool:\n",
    "                condition_logThreshold = np.log10(60) - condition_logThreshold\n",
    "\n",
    "            if linear_scale_bool:\n",
    "            # Convert to linear scale \n",
    "                condition_threshold = 10 ** condition_logThreshold\n",
    "            else:\n",
    "                condition_threshold = condition_logThreshold\n",
    "\n",
    "\n",
    "            # number of trials\n",
    "            trial_sent = condition_data['trialGivenToQuest']\n",
    "            num_trial_sent = sum(str(this_trial) == 'True' for this_trial in trial_sent)\n",
    "            # questSD\n",
    "            questSD = condition_data['questSDAtEndOfTrialsLoop'].dropna().iloc[0]\n",
    "\n",
    "            assert condition_threshold != 0, 'Fatal: Threshold not assigned'\n",
    "\n",
    "            cond_threshold['prolificID'] = prolificID\n",
    "            cond_threshold['conditionName'] = condition_name\n",
    "            cond_threshold['taskName'] = taskName\n",
    "            cond_threshold['meridian'] = meridian\n",
    "            cond_threshold['repeat'] = repeat\n",
    "            cond_threshold['threshold'] = condition_threshold\n",
    "            cond_threshold['numTrialsSent'] = num_trial_sent\n",
    "            cond_threshold['questSD'] = questSD\n",
    "            cond_threshold['readingCQAccuracy'] = np.nan\n",
    "\n",
    "            all_data.append(cond_threshold)\n",
    "\n",
    "            # all_data.append(subj_thresholds)\n",
    "\n",
    "    all_data_df = pd.DataFrame(all_data)\n",
    "\n",
    "    return all_data_df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31027c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOrdReadingSpeed(mydir, files, condition_dict, sessionName, log_bool = True, second_pg_only_bool = False):\n",
    "\t'''\n",
    "\taccuracy_criterion_percent: the reading speed will be marked as np.nan if the accuracy for the comprehension question\n",
    "\t\t\t\t\t\t\t\tis lower than this percentage\n",
    "\twpm_criteiron: the reading speed will be marked as np.nan if it is higher than this percentage\n",
    "\t'''\n",
    "\n",
    "\tcondition_names = list(condition_dict.keys())\n",
    "\n",
    "\tall_data = []\n",
    "\n",
    "\tnumSess = len(files)\n",
    "\tnumThresholdsCat = len(condition_names)\n",
    "\n",
    "\tfor sess in range(numSess):\n",
    "\t\t\n",
    "\t\t# Read the CSV file\n",
    "\t\tfile_path = os.path.join(mydir, files[sess])\n",
    "\t\tmainOutput = pd.read_csv(file_path)\n",
    "\t\tcheckIfComplete(mainOutput)    \n",
    "\t\t\n",
    "\t\tfor cat in range(numThresholdsCat):\n",
    "\n",
    "\t\t\tcond_wpm = {}\n",
    "\t\t\t\t\n",
    "\t\t\tprolificID = mainOutput['ProlificParticipantID'].dropna().iloc[0]\n",
    "\t\t\t\n",
    "\t\t\twordsPerMin = 0\n",
    "\t\t\tcondition_name = condition_names[cat]\n",
    "\t\t\ttaskName, meridian, repeat = parse_condition(condition_name)\n",
    "\t\t\trepeat = sessionName # for reading, the repeats in one session are assigned to the same repeat\n",
    "\n",
    "\t\t\t# Check if the participant answered 3 or more questions correctly\n",
    "\t\t\tquestion_labels = condition_dict[condition_name]\n",
    "\t\t\tnum_questions = len(question_labels)\n",
    "\t\t\tquestion_correct_bool = np.full(num_questions,np.nan)\n",
    "\t\t\tfor qq in range(num_questions):\n",
    "\n",
    "\t\t\t\tqq_data = mainOutput[mainOutput['questionAndAnswerNickname'] == question_labels[qq]]\n",
    "\t\t\t\t\n",
    "\t\t\t\tquestion_correct_bool[qq] = (qq_data['questionAndAnswerCorrectAnswer'].item() == qq_data['questionAndAnswerResponse'].item())\n",
    "\t\t\t\t\n",
    "\t\t\tpercent_correct = sum(question_correct_bool) / num_questions * 100 \n",
    "\t\t\t\n",
    "\t\t\t# calculate reading speed\n",
    "\t\t\tspeed_data = mainOutput[mainOutput['conditionName'] == condition_name]\n",
    "\t\t\tnumWords = speed_data['readingPageWords'].dropna()\n",
    "\t\t\treading_time = speed_data['readingPageDurationOnsetToOffsetSec'].dropna()\n",
    "\n",
    "\t\t\tif second_pg_only_bool:\n",
    "\n",
    "\t\t\t\tnumWords_include = numWords.iloc[1]  # include only 1 page\n",
    "\t\t\t\treading_time_include = reading_time.iloc[1]\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tnumWords_include = numWords.iloc[1:len(numWords)-1]  # exclude first and last page\n",
    "\t\t\t\treading_time_include = reading_time.iloc[1:len(reading_time)-1]\n",
    "\n",
    "\t\t\tnumWords_sum = numWords_include.sum()\n",
    "\t\t\treading_time_sum = reading_time_include.sum()\n",
    "\n",
    "\t\t\treadingSpeed = numWords_sum / (reading_time_sum / 60)\n",
    "\n",
    "\t\t\tassert readingSpeed != 0, 'Fatal: Threshold not assigned'\n",
    "\n",
    "\t\t\tif log_bool:\n",
    "\t\t\t\treadingSpeed = np.log10(readingSpeed)\n",
    "\n",
    "\t\t\tcond_wpm['prolificID'] = prolificID\n",
    "\t\t\tcond_wpm['conditionName'] = condition_name\n",
    "\t\t\tcond_wpm['taskName'] = taskName\n",
    "\t\t\tcond_wpm['meridian'] = meridian\n",
    "\t\t\tcond_wpm['repeat'] = repeat\n",
    "\t\t\tcond_wpm['threshold'] = readingSpeed\n",
    "\t\t\tcond_wpm['numTrialsSent'] = np.nan\n",
    "\t\t\tcond_wpm['questSD'] = np.nan\n",
    "\t\t\tcond_wpm['readingCQAccuracy'] = percent_correct\n",
    "\n",
    "\t\t\tall_data.append(cond_wpm)\n",
    "\t\t\n",
    "\t\tall_data_df = pd.DataFrame(all_data)\n",
    "\t\t\n",
    "\treturn all_data_df\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b0c526",
   "metadata": {},
   "source": [
    "### Acquire thresholds, at a particular trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b68c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No trials sent to QUEST (file name: FreeSilverFish342_67bdf5a74b3f256db8907428_CrowdingReadingAcuity_firstSess20_0001_2025-07-02_19h51.21.712_EDT.csv, condition crowding_R8_block1)\n",
      "Warning: No trials sent to QUEST (file name: FreeSilverFish342_67bdf5a74b3f256db8907428_CrowdingReadingAcuity_firstSess20_0001_2025-07-02_19h51.21.712_EDT.csv, condition crowding_L8_block1)\n",
      "Warning: No trials sent to QUEST (file name: FreeSilverFish342_67bdf5a74b3f256db8907428_CrowdingReadingAcuity_firstSess20_0001_2025-07-02_19h51.21.712_EDT.csv, condition crowding_R8_block2)\n",
      "Warning: No trials sent to QUEST (file name: FreeSilverFish342_67bdf5a74b3f256db8907428_CrowdingReadingAcuity_firstSess20_0001_2025-07-02_19h51.21.712_EDT.csv, condition crowding_L8_block2)\n",
      "Warning: No trials sent to QUEST (file name: FreeSilverFish342_67bdf5a74b3f256db8907428_CrowdingReadingAcuity_firstSess20_0001_2025-07-02_19h51.21.712_EDT.csv, condition acuity_R8_block1)\n",
      "Warning: No trials sent to QUEST (file name: FreeSilverFish342_67bdf5a74b3f256db8907428_CrowdingReadingAcuity_firstSess20_0001_2025-07-02_19h51.21.712_EDT.csv, condition acuity_L8_block1)\n",
      "Warning: No trials sent to QUEST (file name: UpBronzeWhale573_5e38397719e44f0244389781_CrowdingReadingAcuity_secondSess13_0001_2025-07-01_17h48.33.278_ADT.csv, condition crowding_R8_block3)\n",
      "Warning: No trials sent to QUEST (file name: UpBronzeWhale573_5e38397719e44f0244389781_CrowdingReadingAcuity_secondSess13_0001_2025-07-01_17h48.33.278_ADT.csv, condition crowding_L8_block3)\n",
      "Warning: No trials sent to QUEST (file name: UpBronzeWhale573_5e38397719e44f0244389781_CrowdingReadingAcuity_secondSess13_0001_2025-07-01_17h48.33.278_ADT.csv, condition crowding_R8_block4)\n",
      "Warning: No trials sent to QUEST (file name: UpBronzeWhale573_5e38397719e44f0244389781_CrowdingReadingAcuity_secondSess13_0001_2025-07-01_17h48.33.278_ADT.csv, condition crowding_L8_block4)\n",
      "Warning: No trials sent to QUEST (file name: UpBronzeWhale573_5e38397719e44f0244389781_CrowdingReadingAcuity_secondSess13_0001_2025-07-01_17h48.33.278_ADT.csv, condition acuity_R8_block2)\n",
      "Warning: No trials sent to QUEST (file name: UpBronzeWhale573_5e38397719e44f0244389781_CrowdingReadingAcuity_secondSess13_0001_2025-07-01_17h48.33.278_ADT.csv, condition acuity_L8_block2)\n"
     ]
    }
   ],
   "source": [
    "# first session\n",
    "\n",
    "thresholds_names_sess1 = ['crowding_R8_block1','crowding_L8_block1',\n",
    "                          'crowding_R8_block2','crowding_L8_block2',\n",
    "                          'acuity_R8_block1','acuity_L8_block1']\n",
    "df_firstSess = getThresholds(dir_firstSess, files_firstSess, thresholds_names_sess1)\n",
    "\n",
    "thresholds_rsvp_sess1 = ['rsvp_foveal_block1']\n",
    "df_firstSess_rsvp = getThresholds(dir_firstSess, files_firstSess, thresholds_rsvp_sess1, staircase_length=9, convert_to_wpm_bool=True)\n",
    "\n",
    "thresholds_names_read1 = {\n",
    "        'reading_Beaver_block1': ['Beaver_1','Beaver_2','Beaver_3','Beaver_4','Beaver_5'],\n",
    "        'reading_Winter_block2': ['Winter_1','Winter_2','Winter_3','Winter_4','Winter_5']}\n",
    "df_firstSess_reading = getOrdReadingSpeed(dir_firstSess, files_firstSess, thresholds_names_read1, 1, second_pg_only_bool=True)\n",
    "\n",
    "# second session\n",
    "\n",
    "thresholds_names_sess2 = ['crowding_R8_block3','crowding_L8_block3',\n",
    "                          'crowding_R8_block4','crowding_L8_block4',\n",
    "                          'acuity_R8_block2','acuity_L8_block2']\n",
    "df_secondSess = getThresholds(dir_secondSess, files_secondSess, thresholds_names_sess2)\n",
    "\n",
    "thresholds_rsvp_sess2 = ['rsvp_foveal_block2']\n",
    "df_secondSess_rsvp = getThresholds(dir_secondSess, files_secondSess, thresholds_rsvp_sess2, staircase_length=9, convert_to_wpm_bool=True)\n",
    "\n",
    "thresholds_names_read2 = {\n",
    "        'reading_Desert_block1': ['Desert_1','Desert_2','Desert_3','Desert_4','Desert_5'],\n",
    "        'reading_Islands_block2': ['Islands_1','Islands_2','Islands_3','Islands_4','Islands_5']}\n",
    "df_secondSess_reading = getOrdReadingSpeed(dir_secondSess, files_secondSess, thresholds_names_read2, 2, second_pg_only_bool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a6d95c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if you wanted to use logged thresholds.\n"
     ]
    }
   ],
   "source": [
    "# merge data frames\n",
    "\n",
    "df_all_sessions = pd.concat([df_firstSess, df_firstSess_rsvp, df_firstSess_reading,\n",
    "                              df_secondSess, df_secondSess_rsvp, df_secondSess_reading], ignore_index=True)\n",
    "\n",
    "# Check if there are any 0 or negative values in df_both_sessions\n",
    "if (df_all_sessions['threshold'] <= 0).any().any():\n",
    "    print(\"Check if you wanted to use logged thresholds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d049cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of participants with both sessions: 169\n"
     ]
    }
   ],
   "source": [
    "# only keep participants who completed both sessions\n",
    "df_both_sessions = df_all_sessions.groupby(\"prolificID\").filter(lambda g: set(g[\"repeat\"]) == {1, 2, 3, 4})\n",
    "\n",
    "# num_thresholds_per_subj = 18\n",
    "# assert df_both_sessions[\"prolificID\"].nunique() == len(df_both_sessions) / num_thresholds_per_subj, 'Fatal: Number of thresholds per subject does not match'\n",
    "\n",
    "print(f'\\nNumber of participants with both sessions: {df_both_sessions[\"prolificID\"].nunique()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "951eae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_sessions_log = df_both_sessions.copy()\n",
    "# if not already log-transformed, do the log transform here\n",
    "# df_both_sessions_log['threshold'] = np.log10(df_both_sessions_log['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f807f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update meridian values for reading tasks\n",
    "df_both_sessions_log.loc[\n",
    "    (df_both_sessions['taskName'] == 'reading') & \n",
    "    (df_both_sessions['meridian'].isin(['Beaver', 'Desert'])),\n",
    "    'meridian'\n",
    "] = 'first'\n",
    "\n",
    "df_both_sessions_log.loc[\n",
    "    (df_both_sessions['taskName'] == 'reading') & \n",
    "    (df_both_sessions['meridian'].isin(['Winter', 'Islands'])),\n",
    "    'meridian'\n",
    "] = 'second'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf013972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "output_path = 'tidy_both_sessions_thresholds_oneThird_trials_log.csv'\n",
    "df_both_sessions_log.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
